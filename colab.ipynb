{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "65CU-n-JHhbY",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Environment Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i9ati3HcgnAU",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/1595258509/VITS_Japanese.git\n",
    "%cd VITS_Japanese\n",
    "%pip install -r requirements.txt\n",
    "!sudo apt-get install espeak -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ek-ejp-ygnAW",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%cd monotonic_align\n",
    "!python setup.py build_ext --inplace\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "uNzbPIxrgnAW",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jzxRFvutgnAX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "nAOAsfdPgnAX",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Unpack dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dCfFLAiRgnAX",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "api_token = {\"username\":\"murlors\",\"key\":\"71cb88bec124c1ef87c68f148fb7bb34\"}\n",
    "import json\n",
    "import zipfile\n",
    "import os\n",
    " \n",
    "if not os.path.exists(\"/root/.kaggle\"):\n",
    "    os.makedirs(\"/root/.kaggle\")\n",
    "with open('/root/.kaggle/kaggle.json', 'w') as file:\n",
    "    json.dump(api_token, file)\n",
    "!chmod 600 /root/.kaggle/kaggle.json\n",
    "\n",
    "%cd /content/VITS_Japanese\n",
    "\n",
    "!kaggle datasets download -d murlors/yosugaharuka --force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pW0UsWDjgnAY",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!unzip yosugaharuka.zip\n",
    "!rm -rf yosugaharuka.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "fOOzT-E5gnAY",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q6VjMLaSgnAZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5hrlGxT0gnAZ",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!/opt/bin/nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3rIYJRignAa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=/content/drive/MyDrive/yosuga_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-K81On7gnAa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!python train_ms.py -c configs/yosuga_base.json -m yosuga_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "oG01qKeWgnAa",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Text to Speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "3z6nZPmcgnAa",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import commons\n",
    "import utils\n",
    "from data_utils import TextAudioLoader, TextAudioCollate, TextAudioSpeakerLoader, TextAudioSpeakerCollate\n",
    "from models import SynthesizerTrn\n",
    "from text.symbols import symbols\n",
    "from text import text_to_sequence\n",
    "\n",
    "from scipy.io.wavfile import write\n",
    "\n",
    "def get_text(text, hps):\n",
    "    text_norm = text_to_sequence(text, hps.data.text_cleaners)\n",
    "    if hps.data.add_blank:\n",
    "        text_norm = commons.intersperse(text_norm, 0)\n",
    "    text_norm = torch.LongTensor(text_norm)\n",
    "    return text_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hps_ms = utils.get_hparams_from_file(\"./configs/yosuga_base.json\")\n",
    "net_g_ms = SynthesizerTrn(\n",
    "    len(symbols),\n",
    "    hps_ms.data.filter_length // 2 + 1,\n",
    "    hps_ms.train.segment_size // hps_ms.data.hop_length,\n",
    "    n_speakers=hps_ms.data.n_speakers,\n",
    "    **hps_ms.model).cuda()\n",
    "_ = net_g_ms.eval()\n",
    "\n",
    "_ = utils.load_checkpoint(\"/content/drive/MyDrive/yosuga_base/G_157000.pth\", net_g_ms, None)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Japanese"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "speaker_id = \"0\" #@param [0, 1, 2, 3, 4, 5, 6]\n",
    "speaker_id = int(speaker_id)\n",
    "text = 'だめだね、だめよ、だめなのよ' #@param {type: 'string'}\n",
    "length_scale = 1.0 #@param {type:\"slider\", min:0.1, max:3, step:0.05}\n",
    "sid = torch.LongTensor([speaker_id]).cuda()\n",
    "stn_tst = get_text(text, hps_ms)\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_tst = stn_tst.unsqueeze(0).cuda()\n",
    "    x_tst_lengths = torch.LongTensor([stn_tst.size(0)]).cuda()\n",
    "    audio = net_g_ms.infer(x_tst, x_tst_lengths, sid=sid, noise_scale=.667, noise_scale_w=0.8, length_scale=length_scale)[0][0,0].data.cpu().float().numpy()\n",
    "ipd.display(ipd.Audio(audio, rate=hps_ms.data.sampling_rate))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Chinese(fake)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import json\n",
    "import pypinyin\n",
    "\n",
    "# pinyin-to-katakana map\n",
    "map_path = 'text/py2kn.json'\n",
    "with open(map_path, 'r', encoding='utf-8') as f:\n",
    "  py2kn_map = json.load(f)\n",
    "\n",
    "def pinyin2kana(text_ch):\n",
    "  '''Pipeline for converting Chinese text to Japanese Romaji'''\n",
    "  # Chinese characters to pinyin\n",
    "  py_raw = pypinyin.pinyin(text_ch, style=pypinyin.NORMAL)\n",
    "  pys = []\n",
    "  for py in py_raw:\n",
    "    py[0] = py[0].replace('\\u200b', '') # 清除空字符\n",
    "    pys.append(py[0])\n",
    "\n",
    "  # katakana to romaji\n",
    "  text_jp = ''\n",
    "  for py in pys:\n",
    "    text_jp += ''.join(py2kn_map[py])\n",
    "\n",
    "  return text_jp\n",
    "\n",
    "\n",
    "speaker_id_ch = \"0\" #@param [0, 1, 2, 3, 4, 5, 6]\n",
    "speaker_id_ch = int(speaker_id_ch)\n",
    "\n",
    "text_ch = '你好，我是春日野穹。' #@param {type: 'string'}\n",
    "length_scale_ch = 1.0 #@param {type:\"slider\", min:0.1, max:3, step:0.05}\n",
    "\n",
    "text_jp = pinyin2kana(text_ch)\n",
    "sid_ch = torch.LongTensor([speaker_id_ch]).cuda()\n",
    "stn_tst_ch = get_text(text_jp, hps_ms)\n",
    "\n",
    "with torch.no_grad():\n",
    "    x_tst_ch = stn_tst_ch.unsqueeze(0).cuda()\n",
    "    x_tst_ch_lengths = torch.LongTensor([stn_tst_ch.size(0)]).cuda()\n",
    "    audio_ch = net_g_ms.infer(x_tst_ch, x_tst_ch_lengths, sid=sid_ch, noise_scale=.667, noise_scale_w=0.8, length_scale=length_scale_ch)[0][0,0].data.cpu().float().numpy()\n",
    "ipd.display(ipd.Audio(audio_ch, rate=hps_ms.data.sampling_rate))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Voice conversion"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from mel_processing import spectrogram_torch\n",
    "from utils import load_wav_to_torch\n",
    "\n",
    "speaker_id = 0\n",
    "audio, sampling_rate = load_wav_to_torch(\"./yosuga_wav/Kasugano_Sora/SR000023.wav\")\n",
    "\n",
    "y = audio / hps_ms.data.max_wav_value\n",
    "y = y.unsqueeze(0).cuda()\n",
    "\n",
    "spec = spectrogram_torch(y, hps_ms.data.filter_length,\n",
    "    hps_ms.data.sampling_rate, hps_ms.data.hop_length, hps_ms.data.win_length,\n",
    "    center=False)\n",
    "spec_lengths = torch.LongTensor([spec.size(-1)]).cuda()\n",
    "sid_src = torch.LongTensor([speaker_id]).cuda()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "speaker_names = ['春日野穹','天女目瑛','依媛奈緒','渚一葉','乃木坂初佳','倉永梢','伊福部やひろ']\n",
    "with torch.no_grad():\n",
    "    sid_tgt = []\n",
    "    audio = []\n",
    "    for i, speaker_name in enumerate(speaker_names):\n",
    "      sid_tgt.append(torch.LongTensor([i]).cuda())\n",
    "      audio.append(net_g_ms.voice_conversion(spec, spec_lengths, sid_src=sid_src, sid_tgt=sid_tgt[i])[0][0,0].data.cpu().float().numpy())\n",
    "print(\"Original SID: %d\" % sid_src.item())\n",
    "ipd.display(ipd.Audio(y[0].cpu().numpy(), rate=hps_ms.data.sampling_rate))\n",
    "for i, speaker_name in enumerate(speaker_names):\n",
    "  if i == speaker_id:\n",
    "    continue\n",
    "  print(\"Converted SID: %d %s\" % (sid_tgt[i].item(), speaker_name))\n",
    "  ipd.display(ipd.Audio(audio[i], rate=hps_ms.data.sampling_rate))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## jtts"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def jtts(text):\n",
    "  speaker_id = \"0\" #@param [0, 1, 2, 3, 4, 5, 6]\n",
    "  speaker_id = int(speaker_id)\n",
    "  stn_tst = get_text(text, hps_ms)\n",
    "  with torch.no_grad():\n",
    "      x_tst = stn_tst.unsqueeze(0).cuda()\n",
    "      x_tst_lengths = torch.LongTensor([stn_tst.size(0)]).cuda()\n",
    "      sid = torch.LongTensor([speaker_id]).cuda()\n",
    "      audio = net_g_ms.infer(x_tst, x_tst_lengths, sid=sid, noise_scale=.667, noise_scale_w=0.8, length_scale=1)[0][0,0].data.cpu().float().numpy()\n",
    "  ipd.display(ipd.Audio(audio, rate=hps_ms.data.sampling_rate))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bnfPUwRegnAd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "jtts(\"人類の偉大さは数字にこそあると言っていい。\")\n",
    "jtts(\"足し、引き、掛け、割り。\")\n",
    "jtts(\"そんな基本から、何かの大きさ、距離の長さ、\")\n",
    "jtts(\"全てを測定する。\")\n",
    "jtts(\"ありとあらゆる存在は数字なしではただの虚無なのだ。\")\n",
    "jtts(\"生は夏の花の如き、死は秋の叶の如く\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fw6dgxOrgnAe",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "jtts(\"吾輩は猫である。名前はまだない\")\n",
    "jtts(\"試験勉強頑張ってくださいね\")\n",
    "jtts(\"私の処女をもらってください\")\n",
    "jtts(\"なんでこんなに慣れてんのよ。私の方が先に好きだったのに\")\n",
    "jtts(\"大変に気分がいい\")\n",
    "jtts(\"私わあやちねねです\")\n",
    "jtts(\"私のおなにいを見ないでください!\")\n",
    "jtts(\"それわどうかな\")\n",
    "jtts(\"授業中に出したら、学校生活終わるなり\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "colab.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}